# MasterThesisADSA2022Batch
This repository contains the code developed for my Masterâ€™s thesis, focusing on enhancing real-time object detection, depth estimation, and multimodal scene understanding. 

The project integrates state-of-the-art models such as DETIC (Detecting Twenty-thousand Classes using Image-level Supervision), CLIP (Contrastive Language-Image Pre-Training), and MiDaS (Monocular Depth Estimation). These models enable comprehensive scene interpretation by leveraging open-vocabulary object detection, text-image similarity matching, and depth estimation.

Key Features:
DETIC: Open-vocabulary object detection with support for detecting a wide range of classes.
CLIP: Text and image embeddings for natural language queries and image-text matching.
MiDaS: Depth estimation for spatial awareness and object localization in 3D space.
Integration of these models allows for real-time scene understanding, making it ideal for applications such as autonomous systems and intelligent robotics.
